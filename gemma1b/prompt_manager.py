import json
import re
from typing import Optional, Tuple

class PromptManager:
    """Class to manage prompt templates and generation for the nutrition task."""
    
    def __init__(self):
        # Base prompt template without the query
        self.base_prompt = (
            "<bos><start_of_turn>user\n"
            "For the given query including a meal description, think step by step as follows:\n"
            "1. Parse the meal description into discrete food or beverage items along with their serving size. "
            "If the serving size of any item in the meal is not specified, assume it is a single standard serving "
            "based on common nutritional guidelines (e.g., USDA). Ignore additional information that doesn't relate "
            "to the item name and serving size.\n"
            "2. For each food or beverage item in the meal, calculate the amount of carbohydrates in grams for the "
            "specific serving size.\n"
            '3. For the total carbohydrates, respond with just the numeric amount of carbohydrates without extra text. '
            'If you don\'t know the answer, set the value of "total_carbohydrates" to -1.\n'
            '4. Always respond in the users original natural language of the Query. \n'
            "5. Respond with a dictionary object containing the total carbohydrates in grams as follows:\n"
            '{"total_carbohydrates": total grams of carbohydrates for the serving}\n\n'

            # Example 1
            'Query: "This morning, I had a cup of oatmeal with half a sliced banana and a glass of orange juice."\n'
            "Answer:<cot>\n"
            "The meal consists of 1 cup of oatmeal, 1/2 a banana and 1 glass of orange juice.\n"
            "1 cup of oatmeal has 27g carbs.\n"
            "1 banana has 27g carbs so half a banana has (27*(1/2)) = 13.5g carbs.\n"
            "1 glass of orange juice has 26g carbs.\n"
            "So the total grams of carbs in the meal = (27 + 13.5 + 26) = <66.5>g carbs\n"
            "</cot>\n"
            '<answer>Output: {"total_carbohydrates": 66.5}</answer>\n\n'

            # Example 2
            'Query: "朝食に、卵2個で作ったスクランブルエッグとトーストを食べました。"\n'
            "Answer:<cot>\n"
            "その食事は卵2個で作ったスクランブルエッグと1枚のトーストで構成されています。\n"
            "卵2個で作ったスクランブルエッグには2gの炭水化物があります。\n"
            "1枚のトーストには13gの炭水化合物があります。\n"
            "よって、その食事に含まれる炭水化合物の総量は = (2 + 13) = <15>g です\n"
            "</cot>\n"
            '<answer>Output: {"total_carbohydrates": 15}</answer>\n\n'

            # Example 3
            'Query: "半个花生酱和果酱三明治。"\n'
            "Answer:<cot>\n"
            "这份餐点由1/2的花生酱和果酱三明治组成。\n"
            "1个花生酱和果酱三明治含有50.6g碳水化合物，所以半个花生酱和果酱三明治\n"
            "含有(50.6*(1/2)) = <25.3>g碳水化合物\n"
            "因此，这份餐所含的碳水化合物总量 = <25.3>g碳水化合物\n"
            "</cot>\n"
            '<answer>Output: {"total_carbohydrates": 25.3}</answer>\n\n'
        )

    def build_prompt(self, query: str) -> str:
        """
        Build the complete prompt by appending the query to the base prompt.
        
        Args:
            query: The user's meal query text
            
        Returns:
            Complete prompt ready for model input
        """
        return (
            self.base_prompt
            + 'Query: "'
            + query
            + '"\n'
            "<end_of_turn>\n"
            "<start_of_turn>model\n"
            "Answer:<cot>\n"
        )
    
    def build_training_sample(self, query: str, cot: str, answer_value: str, eos_token: str) -> str:
        """
        Build a complete training sample with prompt, COT, and answer.
        
        Args:
            query: The user's meal query text
            cot: The chain-of-thought reasoning text
            answer_value: The carbohydrate value to include in answer
            eos_token: The model's end-of-sequence token
            
        Returns:
            Complete formatted training sample
        """
        prompt = self.build_prompt(query)
        result_json = {"total_carbohydrates": answer_value.strip()}
        
        return (
            prompt
            + (cot if cot else "")
            + "\n</cot>\n"
            + "<answer>Output: "
            + json.dumps(result_json)
            + "</answer><end_of_turn>"
            + eos_token
        )

    def extract_model_block(self, generated_text: str) -> str:
        """
        Extract the <start_of_turn>model...</end_of_turn> block from the generated text.
        
        Args:
            generated_text: The full text generated by the model
            
        Returns:
            The extracted model block, or empty string if not found
        """
        start_marker = "<start_of_turn>model"
        end_marker = "<end_of_turn>"

        start_idx = generated_text.find(start_marker)
        if start_idx == -1:
            return ""

        end_idx = generated_text.find(end_marker, start_idx)
        if end_idx == -1:
            return generated_text[start_idx:]
        else:
            return generated_text[start_idx:end_idx + len(end_marker)]

    def parse_cot_and_answer(self, generated_text: str, verbose=False, log_fn=None) -> Tuple[str, str]:
        """
        Extract the chain-of-thought and answer from generated text.
        
        Args:
            generated_text: The full text generated by the model
            verbose: Whether to log additional information
            log_fn: Optional function to use for logging (like accelerator.print)
            
        Returns:
            Tuple of (chain_of_thought, final_answer)
        """
        if verbose and log_fn:
            log_fn("---------")
            words = generated_text.split()
            if len(words) > 20:
                first_part = " ".join(words[:10])
                last_part = " ".join(words[-10:])
                log_fn(f"generated_text: {first_part} ... {last_part}")
            else:
                log_fn(f"generated_text: {generated_text}")
            log_fn("---------")

        # First extract the model block
        model_block = self.extract_model_block(generated_text)
        
        # Then find the COT and answer sections
        match_cot = re.search(r"<cot>(.*?)</cot>", model_block, flags=re.DOTALL)
        chain_of_thought = match_cot.group(1).strip() if match_cot else ""

        match_ans = re.search(r"<answer>(.*?)</answer>", model_block, flags=re.DOTALL)
        final_answer = match_ans.group(1).strip() if match_ans else ""

        if verbose and log_fn:
            log_fn(f"cot:\n{chain_of_thought}")
            log_fn(f"ans:\n{final_answer}")
            
        return chain_of_thought, final_answer

    def extract_carbs_from_answer(self, answer_text: str) -> Optional[float]:
        """
        Extract the carbohydrate value from an answer text.
        
        Args:
            answer_text: The text of the answer section
            
        Returns:
            The extracted carbohydrate value as a float, or None if not found
        """
        pattern = r'"total_carbohydrates":\s*"?([\d\.]+)"?'
        match = re.search(pattern, answer_text)
        if match:
            try:
                return float(match.group(1))
            except ValueError:
                pass
        return None 